---
# =============================================================================
# Join worker node to the cluster
# =============================================================================
# Usage:
#   ansible-playbook -i hosts.yaml playbooks/worker-join.yaml --limit k8s-worker-2
# =============================================================================

# =============================================================================
# Play 0: Pre-check - validate target is a worker node
# =============================================================================
- name: Pre-check - validate target
  hosts: all
  gather_facts: false

  tasks:
    - name: Fail if no limit specified
      fail:
        msg: "Usage: ansible-playbook -i hosts.yaml playbooks/worker-join.yaml --limit <worker_node>"
      when: ansible_limit is not defined
      run_once: true

    - name: Fail if not a worker node
      fail:
        msg: "ERROR: {{ inventory_hostname }} is not in 'workers' group"
      when: inventory_hostname not in groups['workers']

    - name: Confirm target
      debug:
        msg: "Adding worker node: {{ inventory_hostname }}"

# =============================================================================
# Play 1: Determine master manager
# =============================================================================
- name: Determine master manager
  hosts: all
  gather_facts: false

  tasks:
    - name: Find master manager
      set_fact:
        master_manager_fact: "{{ item }}"
      loop: "{{ groups['managers'] }}"
      when: hostvars[item].is_master | default(false)
      run_once: true

    - name: Fail if no master manager found
      fail:
        msg: "ERROR: No manager with is_master: true found in hosts.yaml"
      when: master_manager_fact is not defined
      run_once: true

    - name: Print master manager
      debug:
        msg: "Master manager: {{ master_manager_fact }}"
      run_once: true

# =============================================================================
# Play 2: Get join command and check existing nodes
# =============================================================================
- name: Get cluster info
  hosts: all
  become: true
  gather_facts: false

  tasks:
    # Get existing nodes from manager
    - name: Get cluster nodes
      command: kubectl get nodes -o jsonpath='{.items[*].metadata.name}'
      delegate_to: "{{ master_manager_fact }}"
      register: cluster_nodes_result
      changed_when: false
      run_once: true

    - name: Set existing nodes as fact
      set_fact:
        existing_nodes_fact: "{{ cluster_nodes_result.stdout.split() }}"

    - name: Print existing nodes
      debug:
        msg: "Nodes in cluster: {{ existing_nodes_fact }}"
      run_once: true

    # Get join command from manager
    - name: Generate join command
      command: kubeadm token create --print-join-command
      delegate_to: "{{ master_manager_fact }}"
      register: join_command_result
      changed_when: false
      run_once: true

    - name: Set join command as fact
      set_fact:
        kubeadm_join_command_fact: "{{ join_command_result.stdout }}"

    - name: Print join command
      debug:
        msg: "{{ kubeadm_join_command_fact }}"
      run_once: true

# =============================================================================
# Play 3: Join worker to cluster
# =============================================================================
- name: Join worker to cluster
  hosts: workers
  become: true

  tasks:
    - name: Check if already joined
      set_fact:
        is_already_joined_fact: "{{ new_hostname in existing_nodes_fact }}"

    - name: Skip if already joined
      debug:
        msg: "{{ new_hostname }} is already in cluster - skipping"
      when: is_already_joined_fact

    - name: Join cluster
      command: "{{ kubeadm_join_command_fact }}"
      register: join_result
      when: not is_already_joined_fact

    - name: Print join result
      debug:
        msg: "{{ join_result.stdout_lines }}"
      when: not is_already_joined_fact and join_result.stdout_lines is defined

    # Verify kubelet
    - name: Wait for kubelet
      pause:
        seconds: 10
      when: not is_already_joined_fact

    - name: Check kubelet status
      command: systemctl is-active kubelet
      register: kubelet_status
      changed_when: false
      failed_when: false

    - name: Assert kubelet is running
      assert:
        that:
          - kubelet_status.stdout == 'active'
        fail_msg: "kubelet is NOT running!"
        success_msg: "{{ new_hostname }}: kubelet running"

    # Apply node labels
    - name: Apply node labels
      command: "kubectl label nodes {{ new_hostname }} {{ item }} --overwrite"
      delegate_to: "{{ master_manager_fact }}"
      loop: "{{ node_labels | default([]) }}"
      when: node_labels is defined and node_labels | length > 0
      register: label_result
      failed_when: false

    - name: Print applied labels
      debug:
        msg: "Applied labels to {{ new_hostname }}: {{ node_labels }}"
      when: node_labels is defined and node_labels | length > 0

    # Apply Longhorn default node tags
    - name: Apply Longhorn default node tags annotation
      command: >-
        kubectl annotate nodes {{ new_hostname }}
        node.longhorn.io/default-node-tags='{{ longhorn_default_tags | to_json }}'
        --overwrite
      delegate_to: "{{ master_manager_fact }}"
      when: longhorn_default_tags is defined and longhorn_default_tags | length > 0
      register: longhorn_tags_result
      failed_when: false

    - name: Print applied Longhorn tags
      debug:
        msg: "Applied Longhorn tags to {{ new_hostname }}: {{ longhorn_default_tags }}"
      when: longhorn_default_tags is defined and longhorn_default_tags | length > 0


# =============================================================================
# Play 4: Verify on manager
# =============================================================================
- name: Verify cluster nodes
  hosts: all
  become: true
  gather_facts: false

  tasks:
    - name: Wait for node registration
      pause:
        seconds: 5
      run_once: true

    - name: Get cluster nodes
      command: kubectl get nodes -o wide
      delegate_to: "{{ master_manager_fact }}"
      register: final_nodes_result
      changed_when: false
      run_once: true

    - name: Print cluster status
      debug:
        msg:
          - "=== Cluster Nodes ==="
          - "{{ final_nodes_result.stdout_lines }}"
      run_once: true
